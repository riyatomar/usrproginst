(1) create a virtual environment inside the "usrproginst" folder using following commands:
	cd usrproginst
	python3 -m venv venv
	source venv/bin/activate


(2) Now, install iscnlp tokenizer, pos-tagger and parser 
	Please follow the given repository link for the same [https://bitbucket.org/iscnlp/].
	
First, install the tokenizer, then the pos-tagger, and then the parser.	
	
Now read the readme given in the repository for all the three (tokenizer, pos-tagger, parser) and run the given commands in 		terminal.
	
Note: Run first command in home directory itself
->>>>>>> (Remember to replace python with python3 while running 3rd step of Readme for all 3 i.e tokenizer, pos-tagger,parser i.e sudo python3 setup.py install) 

Note: While running 3rd command if you get error related to setuptools means pip is not installed in your system then run the following command :-
        sudo apt install python3-pip
 
	In pos-tagger and parser,run the dependencies code after installing them with given command:
	       $ pip install -r requirements.txt

		
(3) Files and folders creation
->>>> After installing, create a input file named "sentences_for_USR" that contains Hindi Sentence/sentences with their respective IDs separated by double space.
		Eg. 123  राम खाना खाता है |

->>>> Now make one folder within "usrproginst" folder named "txt_files" and a text file named "bh-1" inside the same folder (i.e txt_files) for the generation of single USR.

->>>> Make two folder named "bulk_USRs" and "bulk_USRs_mod" in the "usrproginst folder" for bulk generation.
 
->>>> Also make one text file named "bh-2" within "usrproginst" folder for temporary use.

(4) Run the following commands on terminal inside usrproginst folder:
	i) sudo apt install python2
	ii) sudo snap install curl
	iii) curl https://bootstrap.pypa.io/pip/2.7/get-pip.py --output get-pip.py
	iv) sudo python2 get-pip.py
	v) sudo apt-get install python-requests
	vi) sudo bash install-project.sh

(5) To run the NER model, install the transformers and torch using following command:
	pip3 install transformers
	pip3 install torch
	if any error occurred then run the following command:
		pip3 install transformers[torch]
		
(6) Run the following command to compile the apertium:
	sh compile_dict.sh

(7) Run the following command to install wxconv:
	pip3 install WXC
	pip3 install wxconv
			
(8) Copy wx_utf8, utf8_wx and ir_no@ files to bin folder by running the following command on terminal.
	i) cd /usr/bin/
	ii) sudo cp ~/usrproginst/wx_utf8 .
	iii) sudo cp ~/usrproginst/utf8_wx .
	iv) sudo cp ~/usrproginst/ir_no@ .
After running the above commands now run the following commands:- 
	i) sudo chmod +777 utf8_wx
	ii) sudo chmod +777 wx_utf8 
	iii) sudo chmod +777 ir_no@		

(9) Concept checker insatallion
->>>> Run the following commands on terminal within usrproginst:
	i) sudo apt-get -f install apertium-all-dev
	ii) apt-cache policy | grep apertium
	iii) sudo apt-get install python3-openpyx		
	iv) lt-comp lr apertium-eng.eng.dix eng.bin

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Steps for Generating concept row:

(i) Keep the Hindi sentence in the bh-1 file within "txt_files" folder
(ii) Run the following command on the terminal:
	python3 generate_concept_row.py

To generate rest of the rows, run the following command:
	python3 row3_to_row11.py



   
